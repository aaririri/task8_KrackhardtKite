# -*- coding: utf-8 -*-
"""task8_A.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wkPRFnCrrqCfiRoMJyjnLnSO78f6C_UL
"""

!pip install torch-geometric

import torch
from torch_geometric.datasets import TUDataset
from torch_geometric.utils import to_networkx
import networkx as nx
import collections

def weisfeiler_lehman_hash(graph):
    colors = {node: data.get('label', 0) for node, data in graph.nodes(data=True)}

    for _ in range(len(graph.nodes())): # Iterate enough times for convergence
        new_colors = {}
        for node in graph.nodes():
            neighbor_colors = sorted([colors[nbr] for nbr in graph.neighbors(node)])
            signature = (colors[node], tuple(neighbor_colors))
            new_colors[node] = hash(signature) # Hash the signature to get a new color

        if new_colors == colors:
            break
        colors = new_colors

    canonical_hash = str(sorted(colors.values()))
    return canonical_hash

def find_isomorphic_groups_from_pyg(dataset):
    hashes = collections.defaultdict(list)

    for i, data in enumerate(dataset):
        g = to_networkx(data, node_attrs=['x'])

        nx.set_node_attributes(g, {j: int(x[0]) for j, x in enumerate(data.x)}, 'label')

        if len(g) > 0:
            h = weisfeiler_lehman_hash(g)
            hashes[h].append(i)

    isomorphic_groups = {h: indices for h, indices in hashes.items() if len(indices) > 1}
    return isomorphic_groups

import random
import copy

def perturb_graph_add_edge_or_remove(graph, graph_id=None, copy_id=None):
    g = copy.deepcopy(graph)
    nodes = list(g.nodes())
    if random.choice(["add", "remove"]) == "add":
        possible_edges = [(u, v) for i, u in enumerate(nodes) for v in nodes[i+1:]
                          if not g.has_edge(u, v)]
        if not possible_edges:
            if graph_id is not None:
                print(f"Graph {graph_id} Copy {copy_id}: No edge could be added (graph already complete).")
            return g
        edge_to_add = random.choice(possible_edges)
        g.add_edge(*edge_to_add)
        if graph_id is not None:
            print(f"Graph {graph_id} Copy {copy_id}: Added edge {edge_to_add}")
    else:
        if g.number_of_edges() == 0:
            if graph_id is not None:
                print(f"Graph {graph_id} Copy {copy_id}: No edge could be removed (graph has no edges).")
            return g
        edge_to_remove = random.choice(list(g.edges()))
        g.remove_edge(*edge_to_remove)
        if graph_id is not None:
            print(f"Graph {graph_id} Copy {copy_id}: Removed edge {edge_to_remove}")
    return g


def generate_perturbed_collection_from_nx(nx_graphs, largest_group, num_copies=10):
    all_graphs = []
    for idx, g in zip(largest_group, nx_graphs):
        all_graphs.append((f"orig-{idx}", g))
        for copy_id in range(1, num_copies + 1):
            pert_g = perturb_graph_add_edge_or_remove(g, graph_id=idx, copy_id=copy_id)
            all_graphs.append((f"pert-{idx}-{copy_id}", pert_g))
    print(f"\nGenerated {len(all_graphs)} graphs "
          f"({len(nx_graphs)} originals + {len(nx_graphs) * num_copies} perturbed).")
    return all_graphs


def run_wl_on_collection(graphs):
    hashes = collections.defaultdict(list)
    for graph_id, g in graphs:
        if len(g) > 0:
            h = weisfeiler_lehman_hash(g)
            hashes[h].append(graph_id)
    isomorphic_groups = {h: ids for h, ids in hashes.items() if len(ids) > 1}
    print("\nWL Test Results After Perturbation:")
    print(f"  - Total groups found: {len(isomorphic_groups)}")
    total_graphs = sum(len(ids) for ids in isomorphic_groups.values())
    print(f"  - Total graphs inside groups: {total_graphs}")
    if isomorphic_groups:
        print("\n  Group details:")
        for i, ids in enumerate(isomorphic_groups.values(), 1):
            print(f"    Group {i}: {ids}")
    return isomorphic_groups

if __name__ == "__main__":
    print("1. Loading AIDS dataset...")
    dataset = TUDataset(root='/tmp/AIDS', name='AIDS', use_node_attr=True)

    print("2. Finding isomorphic groups...")
    isomorphic_groups = find_isomorphic_groups_from_pyg(dataset)

    if not isomorphic_groups:
        print("   No isomorphic groups found.")
    else:
        num_isomorphic_groups = len(isomorphic_groups)
        total_graphs_in_groups = sum(len(indices) for indices in isomorphic_groups.values())
        print(f"   - Total Isomorphic Groups Found: {num_isomorphic_groups}")
        print(f"   - Total Graphs in Isomorphic Groups: {total_graphs_in_groups}")

        print("\n   Isomorphic Group Details (Graph Indices):")
        sorted_groups = sorted(isomorphic_groups.values(), key=lambda x: x[0])
        for i, group in enumerate(sorted_groups):
            print(f"     - Group {i+1}: {group}")

largest_group = max(isomorphic_groups.values(), key=len)
print(f"Largest isomorphic group has {len(largest_group)} graphs: {largest_group}")

nx_graphs = []
for idx in largest_group:
    data = dataset[idx]
    g = to_networkx(data, node_attrs=['x'])
    nx.set_node_attributes(g, {j: int(x[0]) for j, x in enumerate(data.x)}, 'label')
    nx_graphs.append(g)

print("\nGenerating perturbed copies...")
all_graphs = generate_perturbed_collection_from_nx(nx_graphs, largest_group, num_copies=10)
print(f"Generated {len(all_graphs)} graphs in total "
      f"({len(nx_graphs)} originals + {len(nx_graphs) * 10} perturbed).")

perturbed_groups = run_wl_on_collection(all_graphs)

print("\nChecking original–perturbed isomorphism preservation...")

group_lookup = {}
for group in perturbed_groups.values():
    for gid in group:
        group_lookup[gid] = group

broken_count = 0
total_originals = len(largest_group)

for orig_idx in largest_group:
    orig_id = f"orig-{orig_idx}"
    pert_ids = [f"pert-{orig_idx}-{copy_id}" for copy_id in range(1, 11)]

    group = group_lookup.get(orig_id, None)

    if group is None:
        broken_count += 1
        print(f"  Original {orig_id}: no longer in any isomorphic group.")
    else:
        if not all(pid in group for pid in pert_ids):
            broken_count += 1
            missing = [pid for pid in pert_ids if pid not in group]
            print(f"  Original {orig_id}: broke isomorphism with {len(missing)} perturbed copies.")

print(f"\nNumber of original–perturbed relationships broken: {broken_count} out of {total_originals} originals.")

print(f"\nSummary:")
print(f"  - Broken original–perturbed relationships: {broken_count} out of {total_originals}")
print(f"  - Preserved (still isomorphic): {preserved_count} out of {total_originals}")

"""#All isomorphic relationships break because WL detects even a single edge addition/removal as a structural change. The new graph has a different neighborhood coloring sequence, leading to a different WL hash. Hence, none of the perturbed graphs stay in the same isomorphic group as the originals."""

